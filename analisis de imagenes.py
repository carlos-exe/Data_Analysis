# -*- coding: utf-8 -*-
"""Taller3parte1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1InUBSYekuJIOC5uI9PSwAr_OleUp8gmx
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
# %matplotlib inline
import matplotlib.pyplot as plt
import warnings
from sklearn.datasets import fetch_lfw_people
from sklearn.model_selection import train_test_split
from tensorflow import keras
warnings.filterwarnings("ignore")

"""# Obtención y preprocesado de datos"""

lfw_people = fetch_lfw_people(min_faces_per_person=70, color=True, resize=1.0,
                              slice_=(slice(48, 202), slice(48, 202)))

imagenes = lfw_people.images
y = lfw_people.target
nombres = lfw_people.target_names
clases = nombres.shape[0]

"""Se cuenta con las imágenes y su correspondiente caracterización, a partir de eso se realiza el análisis de su estructura:"""

imagenes.shape

"""Se cuenta con 1288 imágenes, 154 píxeles de altura y 154 de ancho.
Se realiza la correcta estandarización de una imagen determinada, pasándola a formato RGB.
"""

x = imagenes/255
i = np.random.randint(len(lfw_people.images))
plt.imshow(x[i])
plt.grid(False)
print(nombres[y[i]])

"""Es importante resaltar en este punto, que realmente se tienen pocas imágenes para cada una de las clases, tal y como podemos ver a continuación:"""

valores = np.zeros(len(nombres))
for indice,nombre in enumerate(nombres):
  print("Imágenes de", nombre, ": ", x[y==indice].shape[0])
  valores[indice] = x[y==indice].shape[0]

"""Se logra observar que cada clase está compuesta de un número pequeño de imágenes, por esta razón se busca aumentar las entradas de las clases con las transformaciones aleatorias de keras.preprocessing.image.ImageDataGenerator para así producir modificaciones y generalizar el modelo.
Modificaciones:
- rotation_rang: Rango máximo de giro permitido en grados.
- width_shift y height_shift:Rango máximo de traslación vertical y horizontal.
- Shear_range: Rango máximo de mapeo de corte, aplicación lineal que desplaza cada punto en una dirección fija.
- horizontal_flip: Activa la posibilidad de tornar la imagen de manera horizontal.
-fill_mode: Mecanismo de llenado de nuevos píxeles creados.
-reshape: Multiplica los valores RGB de la imagen, estandarizando de 0 a 1.
"""

from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img
datagen = ImageDataGenerator(
        rescale=1./255,
        rotation_range=40,
        width_shift_range=0.2,
        height_shift_range=0.2,
        shear_range=0.2,
        zoom_range=0.2,
        horizontal_flip=True,
        fill_mode='nearest')

z = x[6][None]
i = 0
fig,axes = plt.subplots(nrows = 1, ncols = 5, figsize=(15,15))
for ax in axes.flatten():
    ax.axis('off')
for batch in datagen.flow(z, batch_size=1):
    axes[i].imshow(batch[0]*255)
    i +=1
    if i > 4:
        break

_ = plt.hist(y, bins=clases)

"""Se logra ver un desbalance en las clases debido al sobreajuste realizado, esto se resuelve con RandomOverSampler, el cual permitirá la sobremuestra con muestras aleatorias con su reemplazo, luego podrán modificarse satisfactoriamente."""

from imblearn.over_sampling import RandomOverSampler
n_classes = clases
sampling_targets = np.maximum([250] * n_classes, np.bincount(y))
ratio_dict = dict(zip(range(n_classes), sampling_targets))
ros = RandomOverSampler(ratio=ratio_dict, random_state=42)
xnew_shape = imagenes.shape
xnew = np.reshape(imagenes, (xnew_shape[0], -1))
xnew, ynew = ros.fit_sample(xnew, y)
xnew = np.reshape(xnew, (len(xnew),) + xnew_shape[1:])

_ = plt.hist(ynew, bins=n_classes)

"""Con esto se logra solucionar el sobreajuste con normalización de 250 datos, lo que implica un dataset mayor.Luego de esto se realiza la codificación por one hot encoding."""

from sklearn.model_selection import train_test_split

test_split = 0.2
data = imagenes
n_classes = nombres.shape[0]
X_train, X_test, y_train, y_test = train_test_split(data, y, test_size=test_split,
                                                    stratify=y, random_state=42)

sampling_targets = np.maximum([256] * n_classes, np.bincount(y_train))
ratio_dict = dict(zip(range(n_classes), sampling_targets))
ros = RandomOverSampler(ratio=ratio_dict, random_state=42)
X_train_shape = X_train.shape
X_train = np.reshape(X_train, (X_train_shape[0], -1))
X_train, y_train = ros.fit_sample(X_train, y_train)
X_train = np.reshape(X_train, (len(X_train),) + X_train_shape[1:])
# one hot encoding
y_train_lin = y_train
y_train = keras.utils.to_categorical(y_train, n_classes)
y_test_lin = y_test
y_test = keras.utils.to_categorical(y_test, n_classes)

"""# Creación del modelo

Utilizando un modelo secuencial ya que el modelo es adecuado para una pila simple de capas donde cada capa tiene exactamente un tensor de entrada y un tensor de salida.
"""

from keras.layers import Conv2D, MaxPooling2D
from keras.layers import Activation, Dropout, Flatten, Dense
from keras.models import Sequential
from keras import Model
model = Sequential()

"""La arquitectura de una RNA es la estructura o patrón de conexiones de la red. Es conveniente recordar que las conexiones sinápticas son direccionales, es decir, la información sólo se transmite en un sentido.

En general, las neuronas suelen agruparse en unidades estructurales llamadas capas. Dentro de una capa, las neuronas suelen ser del mismo tipo. Se pueden distinguir tres tipos de capas:

·        De entrada: reciben datos o señales procedentes del entorno.

·        De salida: proporcionan la respuesta de la red a los estímulos de la entrada.

·        Ocultas: no reciben ni suministran información al entorno (procesamiento interno de la red).

Se establece la capa de entrada con sus parámetros (154x154, 3RGB). Tomando el activador relu que funciona bien en capas ocultas y de entrada y añade 32 filtros con dimensión 3x3. Se añade también la capa de salida y se reduce la dimensión a la mitad.
"""

## Capa convolucional con activación y pooling 1
model.add(Conv2D(32, (3, 3), input_shape=data.shape[1:]))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

"""Se añaden 3 capas más modificando el tamaño de los filtros."""

## Capa convolucional con activación y pooling 2
model.add(Conv2D(32, (3, 3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
## Capa convolucional con activación y pooling 3
model.add(Conv2D(64, (3, 3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
## Capa convolucional con activación y pooling 4
model.add(Conv2D(128, (3, 3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

"""Se obtiene un mapa en 3D, por lo que debe reducirse a una sola dimensión con una capa de aplanada."""

model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors

"""
Se continúa creando una capa para las probabilidades de las clases, se escoge la activación por relu ya que se trata de una capa oculta."""

model.add(Dense(64))
model.add(Activation('relu'))

"""
Para resaltar, es importante tener una capa de Dropout, debido a que en el proceso de aumentación y modificación se pueden obtener imágenes que contengan características similares, esta capa reduce el sobreajuste y actúa de manera análoga al aumento de los datos."""

model.add(Dropout(0.5))

"""
Para la capa de salida se utiliza un activador softmax para variables categóricas."""

model.add(Dense(n_classes))
model.add(Activation('softmax'))

model.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

from keras.utils.vis_utils import plot_model
plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)

"""Nuevamente se definen los parámetros de las modificaciones para iniciar el proceso de aprendizaje."""

datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=10,
    width_shift_range=0.1,
    height_shift_range=0.1,
    shear_range=0.05,
    zoom_range=0.1)

"""Entrenando el modelo, con un batch size de 250 y 100 épocas con pasos de :

\begin{equation}
steps = \frac{\mbox{Conjunto de datos}}{\mbox{Conjunto de lote}}
\end{equation}
"""

batch_size = 250

#entrenamiento
history = model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size),
                    steps_per_epoch=len(X_train) / batch_size,
                    epochs=100,
                    verbose=1,
                    validation_data=(X_test, y_test))

"""la precisión en el conjunto de validación ronda el 95% de exactitud. Este valor de ambos conjuntos varía según las épocas."""

plt.figure(figsize=(10, 10))
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.ylabel('accuracy', fontsize='x-large')
plt.xlabel('epoch', fontsize='x-large')
plt.legend(['train', 'test'], loc='upper left', fontsize='x-large')

y_pred = model.predict(X_test, batch_size=len(X_test), verbose=1)
y_pred = np.argmax(y_pred, axis=1)
def plot_barh(labels, values):
    fig = plt.figure(figsize=(12, 8))
    y_pos = np.arange(len(labels))
    plt.barh(y_pos, values, align='center', alpha=0.5)
    plt.yticks(y_pos, labels)
    plt.xticks(np.arange(0.0, 1.0, 0.05))
    plt.xlabel('accuracy', fontsize='x-large')
    plt.axes().xaxis.grid(color='black', linestyle='-', linewidth=0.5)
    axes = plt.gca()
    axes.set_xlim([0.0, 1.0])
    axes.axvline(np.mean(values), color='green', linewidth=2)
    plt.tight_layout()
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(np.argmax(y_test, axis=1), y_pred)
cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
class_accuracies = [cm[i, i] for i in range(cm.shape[0])]
plot_barh(nombres, class_accuracies)
print("Precisión total máxima (Test_set): :" , np.round(np.max(history.history['val_accuracy'])*100,1),"%" )
print('Precisión media (test_set): {}%'.format(np.round(np.mean(class_accuracies) * 100.0, 1)))

"""## Matriz de confusión"""

def plot_confusion_matrix(cm, classes, cmap=plt.cm.Blues):
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    tick_marks = np.arange(0, len(classes), 2)
    plt.xticks(tick_marks, classes[tick_marks], rotation=90)
    plt.yticks(tick_marks, classes[tick_marks])
    plt.ylabel('True label', fontsize='x-large')
    plt.xlabel('Predicted label', fontsize='x-large')
plt.figure(figsize=(10, 10))
cm = confusion_matrix(np.argmax(y_test, axis=1), y_pred)
cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
plot_confusion_matrix(cm, classes=nombres)
plt.grid(False)

"""# Comparación con otros modelos

Se realiza una comparación del resultado obtenido anteriormente con la regresión logística; por el preprocesado realizado y con el aumento en las imágenes se logran obtener respuestas satisfactorias. Se inicia el proceso de aplanado y se crea un conjunto estratificado:

## Regresión lineal
"""

from sklearn import  svm,metrics
Xtrain, Xtest, ytrain,ytest = train_test_split(imagenes,y,test_size=0.3,stratify=y)
d1, d2, d3, d4 = Xtrain.shape
t1,t2,t3,t4 = Xtest.shape
x_lin_reshaped = Xtrain.reshape((d1, d2*d3*d4))
x_test_reshaped = Xtest.reshape((t1, t2*t3*t4))

from sklearn.linear_model import LogisticRegression
classifier = LogisticRegression(random_state=0,verbose=1)
classifier.fit(x_lin_reshaped, ytrain)

y_pred1 = classifier.predict(x_test_reshaped)

# Commented out IPython magic to ensure Python compatibility.
print("Classification report for classifier %s:\n%s\n"
#       % (classifier, metrics.classification_report(ytest, y_pred1)))

"""Y su precisión total:"""

from sklearn.metrics import accuracy_score
log_reg_acc = accuracy_score(ytest, y_pred1) ## Se calcula loa eficacia
print("La eficacia del modelo es de: " ,log_reg_acc*100 ,"%")

"""## SVM lineal"""

from sklearn.svm import LinearSVC
classifiersvm = LinearSVC(random_state=0, tol=1e-5)
classifiersvm.fit(x_lin_reshaped, ytrain)

y_pred2 = classifiersvm.predict(x_test_reshaped)

# Commented out IPython magic to ensure Python compatibility.
print("Classification report for classifier %s:\n%s\n"
#       % (classifier, metrics.classification_report(ytest, y_pred2)))

from sklearn.metrics import accuracy_score
log_reg_acc = accuracy_score(ytest, y_pred2) ## Se calcula loa eficacia
print("La eficacia del modelo es de: " ,log_reg_acc*100 ,"%")

"""Es importante resaltar que para el modelo de CNN se trabajó sobre un modelo aumentado aleatoriamente para evitar el sobreajuste, y los otros dos modelos reciben los datos sin más. Hay una notable diferencia de efectividad entre los dos métodos, aunque la cantidad de código y esfuerzo computacional también es mucho mayor en el CNN. La eficacia del modelo es de un 89%"""